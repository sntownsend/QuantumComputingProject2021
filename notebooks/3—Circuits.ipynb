{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6023b44e",
   "metadata": {},
   "source": [
    "# Sentences as Circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7fa3c",
   "metadata": {},
   "source": [
    "### Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from discopy.rigid import Ty\n",
    "from discopy.grammar.pregroup import Word\n",
    "from discopy.rigid import Diagram, Id, Cup\n",
    "import yaml\n",
    "import random\n",
    "from math import pi\n",
    "from qnlpws_utils.parse import *\n",
    "from qnlpws_utils.circuits import *\n",
    "import ipywidgets as ipw\n",
    "import pickle\n",
    "from pytket.extensions.qiskit import AerBackend, tk_to_qiskit\n",
    "from pytket.extensions.qsharp import QsharpSimulatorBackend, tk_to_qsharp\n",
    "import numpy as np\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "import noisyopt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71451e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/words.yaml\") as f:\n",
    "    word_data = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27228e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "s, n = Ty('s'), Ty('n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05dc7d",
   "metadata": {},
   "source": [
    "### Create sets of verbs and nouns and sentences\n",
    "\n",
    "- These are simple \"pseudo-sentences\" used by Hoffmann in his thesis, and are stored in two parts:\n",
    "    - A string containing the verb and noun\n",
    "    - An integer (0 or 1) representing the plausibility score of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d153f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, nouns, verbs = parse_dummy_sentences(word_data[\"sub_sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f7535",
   "metadata": {},
   "source": [
    "## Create representation of our words\n",
    "\n",
    "Here, words are added to a dictionary, `vocab`, along with their structure in the DisCoCat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a16168",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_verbs = [\"file\"] \n",
    "\n",
    "# nouns\n",
    "vocab = Vocab({noun: Word(noun, n) for noun in nouns},\n",
    "              {verb: Word(verb, s @ n.l) for verb in verbs if verb not in ambiguous_verbs},\n",
    "              {amb: Word(amb, s @ n.l) for amb in ambiguous_verbs}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fef689",
   "metadata": {},
   "source": [
    "## Prepare and parse dataset\n",
    "### Define a Grammar\n",
    "Here, we define the input pseudo-sentence as consisting of a verb and a left-adjoint-noun and noun pair and parse the sentences accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = Id(s) @ Cup(n.l, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, plausability, parsing = parse_with_grammar(dataset, grammar, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632e71e",
   "metadata": {},
   "source": [
    "### View Sentences\n",
    "\n",
    "The result of this parsing can be seen below. Use the dropdown menu to select which sentence you want to view. Note: for some reason, the dropdown list works on some occasions but not on others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = ipw.Dropdown(options=list(zip(sentences, plausability)))\n",
    "@ipw.interact(p=dc)\n",
    "def view_psentences(p):\n",
    "    print(dc.label,\" plausability: \", p)\n",
    "    parsing[dc.label].draw(draw_type_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f29be",
   "metadata": {},
   "source": [
    "## Creating Circuits\n",
    "### Creating initial parameters\n",
    "The initial values of the parameters for nouns and ambiguous verbs are generated randomly according to a uniform distribution between 0 and 1 using the function create_params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6d240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = \\\n",
    "    create_params(nouns, \n",
    "                  ambiguous_verbs, \n",
    "                  vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffbe74",
   "metadata": {},
   "source": [
    "### Generating the circuits\n",
    "\n",
    "Circuits are created using the function $F$. For the curious, the definition is shown below. You can choose the backend of your choice, but the Q# backend does not include a way of displaying the circuit.\n",
    "\n",
    "```Python\n",
    "def F(vocab,\n",
    "      params,\n",
    "      n_qubits_ansatz=1):\n",
    "    ar1 = {vocab.noun[noun]:noun_ansatz(params.noun[noun]) for noun in vocab.noun}\n",
    "    ar2 = {vocab.unamb_verb[verb]:un_amb_verb_ansatz(params.unamb_verb[verb]) for verb in vocab.unamb_verb}\n",
    "    ar3 = {vocab.amb_verb[verb]:amb_verb_ansatz(params.amb_verb[verb]) for verb in vocab.amb_verb}\n",
    "    ar = {**ar1, **ar2, **ar3}\n",
    "\n",
    "    return CircuitFunctor(\n",
    "        ob = {s: qubit ** 0, n: qubit ** n_qubits_ansatz},\n",
    "        ar = ar)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb6961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits = {s:F(vocab,params)(parsing[s]) for s in sentences}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04897fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qiskit_backend = AerBackend()\n",
    "qsharp_backend = QsharpSimulatorBackend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c063c",
   "metadata": {},
   "source": [
    "### Choose a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c540ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ipw.Dropdown(options=circuits.items(), description=\"sentence\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953aeb23",
   "metadata": {},
   "source": [
    "### Choose the backend\n",
    "Note: Q# backend can't display circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d434d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbe = ipw.Dropdown(options=[\"qiskit\", \"qsharp\"], description=\"backend\")\n",
    "dbe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637f63c",
   "metadata": {},
   "source": [
    "### Create the circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e314bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit = ds.value\n",
    "if dbe.value == \"qsharp\":\n",
    "    backend = qsharp_backend\n",
    "else:\n",
    "    backend = qiskit_backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dc5500",
   "metadata": {},
   "source": [
    "### Render the circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_circuit(circuit, backend):\n",
    "    tk_circ = circuit.to_tk()\n",
    "    print(\"{}:\\n{}\\n\".format(tk_circ, '\\n'.join(map(str, tk_circ))))\n",
    "    print(\"post selection:\\n{}\\n\".format(tk_circ.post_selection))\n",
    "    print(\"scalar:\\n{}\\n\".format(tk_circ.scalar))\n",
    "    print(\"qiskit circuit:\")\n",
    "    if isinstance(backend, AerBackend):\n",
    "        tk_to_qiskit(tk_circ).draw(output=\"mpl\")\n",
    "    else:\n",
    "        print(\"Circuit drawing not implemented for this backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200108c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_circuit(circuit, backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc101f0a",
   "metadata": {},
   "source": [
    "## Optimizing the parameters\n",
    "### Step 1: [Genetic algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm)\n",
    "In this section, a Genetic Algorithm is applied to optimize the parameters for the representation of words as qubits. A genetic algorithm is inspired by natural selection in evolution and uses random mutations in parameters, letting the inadequate mutations die off to hopefully end up with a superior parameter set. These are expensive, however, and the rate of decrease in the error slows after a few iterations, so here its use is limited to 25 iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237643fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(params_np, vocab, n_noun_params = 2, n_amb_params = 1):\n",
    "    ''' Converts numpy array of parameters back to dictionary\n",
    "    '''\n",
    "    n_nouns = len(vocab.noun)\n",
    "    n_amb_verbs = len(vocab.amb_verb)\n",
    "    n_unamb_verbs = len(vocab.unamb_verb)\n",
    "\n",
    "    params_nouns_np = params_np[:n_nouns*n_noun_params].reshape((n_nouns,n_noun_params))\n",
    "    params_amb_verbs_np = params_np[n_nouns*n_noun_params:].reshape((n_amb_verbs,n_amb_params))\n",
    "\n",
    "    params_nouns = {word: params_nouns_np[i].tolist() for i, word in enumerate(vocab.noun.keys())}\n",
    "    params_amb_verbs = {word: params_amb_verbs_np[i].tolist() for i, word in enumerate(vocab.amb_verb)}\n",
    "\n",
    "    return params_nouns, params_amb_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(params_nouns, params_unamb_verbs, params_amb_verbs, \n",
    "             sentences, backend=AerBackend(), n_shots=2**10, seed=0):\n",
    "    global vocab\n",
    "    circuits = [F(vocab, Params(params_nouns, params_unamb_verbs, params_amb_verbs))(parsing[sent]) for sent in sentences]\n",
    "    results = [Circuit.eval(\n",
    "                circuit,\n",
    "                backend=backend,\n",
    "                n_shots=n_shots,\n",
    "                seed=seed,\n",
    "                compilation=backend.default_compilation_pass(2)) for circuit in circuits]\n",
    "    tensors = [np.abs(result.array)[0] for result in results]\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94fe80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params_np):\n",
    "    global circuits\n",
    "    global vocab\n",
    "    global plausability\n",
    "    global backend\n",
    "    global params\n",
    "    global sentences\n",
    "    # convert np to dict\n",
    "    params_nouns, params_amb_verbs = reshape_data(params_np,\n",
    "                                                 vocab,\n",
    "                                                  n_noun_params = 2, n_amb_params = 1 )\n",
    "    return np.mean(np.array([\n",
    "        (plausability[i] - scalar) ** 2\n",
    "        for i, scalar in enumerate(evaluate(params_nouns, \n",
    "                                            params.unamb_verb, \n",
    "                                            params_amb_verbs, \n",
    "                                            sentences,\n",
    "                                            backend))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a5db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(func,\n",
    "              vocab,\n",
    "              n_qubits_ansatz = 1,\n",
    "               n_noun_params = 2,\n",
    "               n_amb_params = 1,\n",
    "               algorithm_param = None):\n",
    "    if algorithm_param == None:\n",
    "        algorithm_param = {\n",
    "            'max_num_iteration': 25,\\\n",
    "            'population_size':5,\\\n",
    "            'mutation_probability':0.1,\\\n",
    "            'elit_ratio': 0.01,\\\n",
    "            'crossover_probability': 0.5,\\\n",
    "            'parents_portion': 0.3,\\\n",
    "            'crossover_type':'uniform',\\\n",
    "            'max_iteration_without_improv':None\n",
    "        }\n",
    "\n",
    "    dimension = n_noun_params*len(vocab.noun) + n_amb_params*len(vocab.amb_verb)\n",
    "    varbound=np.array([[0,1]]*dimension)\n",
    "\n",
    "    return ga(function=func, dimension=dimension, \n",
    "             variable_type='real',\n",
    "             variable_boundaries=varbound, \n",
    "             algorithm_parameters=algorithm_param, \n",
    "             function_timeout=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc8b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(loss, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be19dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d221c",
   "metadata": {},
   "source": [
    "### Step 2: noisyopt\n",
    "\n",
    "noisyopt uses an optimization method that simulates the constraints of optimization problems on a quantum-device. Such algorithms have been proven to work with QNLP on noisy-intermediate-stage quantum (NISQ) computers (Meichanetzidis et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79caeab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, start = 0, time()\n",
    "def callback(loss):\n",
    "    global i\n",
    "    i += 1\n",
    "    print(\"Epoch {} ({:.0f} seconds since start): {}\".format(i, time() - start, loss))\n",
    "\n",
    "result = noisyopt.minimizeSPSA(\n",
    "    loss, model.best_variable, paired=False, callback=callback, niter=200, a=0.2, c=0.1)\n",
    "\n",
    "print(\"Best loss: \", result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss2(params_np, \n",
    "          vocab=vocab,\n",
    "          params=params,\n",
    "          sentences=sentences, \n",
    "          plausability=plausability):\n",
    "\n",
    "    # convert back to dict\n",
    "    params_nouns, params_amb_verbs = reshape_data(params_np, vocab)\n",
    "\n",
    "    return  {sentences[i]:(plausability[i], round(scalar,4))\n",
    "        for i, scalar in enumerate(evaluate(params_nouns, \n",
    "                                            params.unamb_verb, \n",
    "                                            params_amb_verbs, \n",
    "                                            sentences))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d512f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = loss2(result.x, vocab)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8000431a",
   "metadata": {},
   "source": [
    "### Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0882a",
   "metadata": {},
   "source": [
    "The images below show the similarity between this model's interpretation of a sentence's plausibility and the true value. The top image is for a model with a maximum loss of 0.0414 and the bottom is for a model with loss of 0.0153.\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src = amb_results0414.png width = 512></td>\n",
    "        <td><img src = amb_results0153.png width = 512></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align = center> loss = 0.0414 </td>\n",
    "        <td align = center> loss = 0.0153 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "`high` indicates that the verb is not `file` and the sentences is assigned a plausibility of 1.\n",
    "`low` idicates the non-`file` verbs with plausibility 0.\n",
    "`amb` indicates that the verb is `file`."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python (qnlp-ws)",
   "language": "python",
   "name": "qnlp-ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
